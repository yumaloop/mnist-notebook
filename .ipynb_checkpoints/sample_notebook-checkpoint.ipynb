{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras/TensorflowでMNISTデータセットの画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy :\", np.__version__)\n",
    "print(\"pandas :\", pd.__version__)\n",
    "print(\"tensorflow :\", tf.__version__)\n",
    "print(\"matplotlib :\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 実行環境についての設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの学習曲線(後述)を描画できるように,CSVファイルを作成しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = \"trainlog.csv\"\n",
    "if not os.path.exists(CSV_FILE_PATH): \n",
    "    pathlib.Path(CSV_FILE_PATH).touch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. データセットの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflowから実行環境(このファイル)へMNIST Datasetを読み込みましょう．\n",
    "\n",
    "---\n",
    "\n",
    "MNIST Dataset:\n",
    "- trainデータ\n",
    "  - X_train: 手書き数字の白黒画像 60,000枚 -  ${\\left\\{ {\\bf x}_i \\in \\mathbb{R}^{28 \\times 28} \\right\\}}_{i=1 \\sim 60000}$\n",
    "  - y_train: 手書き数字のラベル 60,000個 - ${\\left\\{ y_i \\in [0,1,\\dots,9] \\right\\}}_{i=1 \\sim 60000}$\n",
    "- testデータ\n",
    "  - X_test: 手書き数字の白黒画像 10,000枚 -  ${\\left\\{ {\\bf x}_i \\in \\mathbb{R}^{28 \\times 28} \\right\\}}_{i=1 \\sim 10000}$\n",
    "  - y_test: 手書き数字のラベル 10,000個 - ${\\left\\{ y_i \\in [0,1,\\dots,9] \\right\\}}_{i=1 \\sim 10000}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from tensorflow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "del mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train : \", X_train.shape)\n",
    "print(\"y_train : \", y_train.shape)\n",
    "print(\"X_test : \", X_test.shape)\n",
    "print(\"y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Datasetのサンプル**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X(白黒画像)とy(ラベル)を見てみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in [1,10,100]:\n",
    "    print(\"y_train\", \"(i=\"+str(i)+\"): \", y_train[i])\n",
    "    print(\"X_train\", \"(i=\"+str(i)+\"): \")    \n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 画像データの正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般に，「(扱う)データの値を，何らかの基準に基づいて整える」処理を正規化(Normalization, Scalijng)といいます．代表的な正規化手法としては以下2つが挙げられます．\n",
    "\n",
    "1. min-max normalization\n",
    "   - 最小値が0, 最大値が1になるように変換する\n",
    "   - x_new = (x - x_min) / (x_max - x_min)\n",
    "2. z-score normalization\n",
    "   - 平均が0, 標準偏差が1になるよう変換する\n",
    "   - x_new = (x - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Datasetに含まれる画像データでは，各画素の値が「0以上255以下」の8bit整数で表現されています．今回は，これにmin-max normalizationを適用することで，値の範囲を「0~1」に限定させます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train min\", X_train.min())\n",
    "print(\"X_train max\", X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "X_train, X_test = X_train/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train min\", X_train.min())\n",
    "print(\"X_train max\", X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "model = tf.keras.models.Sequential([\n",
    "    # (None, 28, 28) -> (None, 784)\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name='input'),\n",
    "    \n",
    "    # Layer1: Linear mapping: (None, 784) -> (None, 512)\n",
    "    tf.keras.layers.Dense(512, name='fc_1'),\n",
    "    # Activation function: ReLU\n",
    "    tf.keras.layers.Activation(tf.nn.relu, name='relu_1'),\n",
    "    \n",
    "    # Layer2: Linear mapping: (None, 512) -> (None, 256)\n",
    "    tf.keras.layers.Dense(256, name='fc_2'),\n",
    "    # Activation function: ReLU\n",
    "    tf.keras.layers.Activation(tf.nn.relu, name='relu_2'),\n",
    "    \n",
    "    # Layer3: Linear mapping: (None, 256) -> (None, 256)\n",
    "    tf.keras.layers.Dense(256, name='fc_3'),\n",
    "    # Activation function: ReLU\n",
    "    tf.keras.layers.Activation(tf.nn.relu, name='relu_3'),\n",
    "    \n",
    "    # Layer4: Linear mapping: (None, 256) -> (None, 10)\n",
    "    tf.keras.layers.Dense(10, name='dense_3'),\n",
    "    # Activation function: Softmax\n",
    "    tf.keras.layers.Activation(tf.nn.softmax, name='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "# Set model & training information into machine memory (CPU or GPU)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback functions which are called during model training\n",
    "callbacks = []\n",
    "callbacks.append(tf.keras.callbacks.CSVLogger(CSV_FILE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルにtrainデータを与えて，学習(training)させましょう．\n",
    "\n",
    "- train データ (`X_train`, `y_train`): \n",
    "   - モデル(`model`)の学習(training)に用いる．\n",
    "- test データ (`X_test`, `y_test`): \n",
    "   - モデル(`model`)の性能検証(validation)に用いる．\n",
    "\n",
    "> ```python\n",
    "> # Train model\n",
    "> history = model.fit(...)\n",
    "> ```\n",
    "\n",
    "なお，ニューラルネットワーク$f_{\\theta}: X \\mapsto Y$において，「推論」「学習」とは以下の計算処理を指します．\n",
    "\n",
    "- 推論(inference)とは \n",
    "   - 順伝播(input x → output y)によって，モデルの出力値$y$を計算すること\n",
    "   - $(X,\\theta)$は固定値，$y$に着目\n",
    "- 学習(training)とは\n",
    "   - 逆伝播(output y → input x)によって，モデルのパラメータ$\\theta$を更新すること\n",
    "   - $(X,y)$は固定値，$\\theta$に着目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=30,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 学習済みモデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデル(`model`)のtestデータ(`X_test`,`y_test`)に対するの正答率(accuracy)と損失関数の値(loss)を確認しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"loss(train): {:.4}\".format(train_loss))\n",
    "print(\"accuracy(train): {:.4}\".format(train_acc))\n",
    "\n",
    "print()\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"loss(test): {:.4}\".format(test_loss))\n",
    "print(\"accuracy(test): {:.4}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用意しておいたCSVファイルを元に，学習曲線(モデルに対する評価指標の経過を表す)を描画してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = df[\"epoch\"].values\n",
    "train_acc = df[\"acc\"].values\n",
    "train_loss = df[\"loss\"].values\n",
    "test_acc = df[\"val_acc\"].values\n",
    "test_loss = df[\"val_loss\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**画像分類の正答率**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_loss, label=\"train data\")\n",
    "plt.plot(epochs, test_loss, label=\"test data\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\\n(categorical crossentropy)\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**損失関数の値**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_acc, label=\"train data\")\n",
    "plt.plot(epochs, test_acc, label=\"test data\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 学習済みモデルによる推論計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデルを用いて，testデータに対する推論計算を行い，分類結果をみてみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in [0,1,2]:\n",
    "    y_true = y_test[i]\n",
    "    y_pred = model.predict_classes(X_test[i].reshape(1,28,28))[0]\n",
    "    print(\"y_test_pred\", \"(i=\"+str(i)+\"): \", y_pred)\n",
    "    print(\"y_test_true\", \"(i=\"+str(i)+\"): \", y_true)\n",
    "    print(\"X_test\", \"(i=\"+str(i)+\"): \")    \n",
    "    plt.imshow(X_test[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "ROW = 4\n",
    "COLUMN = 5\n",
    "\n",
    "for i in range(ROW * COLUMN):\n",
    "    y_true = y_test[i]\n",
    "    y_pred = model.predict_classes(X_test[i].reshape(1,28,28))[0]\n",
    "    \n",
    "    if y_true == y_pred:\n",
    "        result = \"True\" # Correct answer from the model\n",
    "    else:\n",
    "        result = \"False\" # Incorrect answer from the model\n",
    "    \n",
    "    plt.subplot(ROW, COLUMN, i+1)\n",
    "    plt.imshow(X_test[i], cmap='gray')\n",
    "    plt.title(\"No.{} - {}\\ny_true:{}, y_pred:{}\".format(i, result, y_true, y_pred))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 学習済みモデルの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kerasでは，全てのニューラルネットワークモデルが`keras.models.Model()`クラスのインスタンスとなっています．学習済みモデル`model`に対して，\n",
    "`model.save()`を実行することで「モデルの保存」が完了します．\n",
    "\n",
    "> ```python\n",
    "> # save model as keras instance\n",
    "> ins_path = 'trained_model_v0.h5'\n",
    "> model.save(ins_path)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
